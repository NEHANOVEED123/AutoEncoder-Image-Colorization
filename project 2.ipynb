{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From E:\\PycharmProjects\\CV-PROJECT-AUTOENCODER\\venv\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import keras\n",
    "import re\n",
    "from keras.preprocessing.image import img_to_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "\n",
    "# to get the files in proper order\n",
    "def sorted_alphanumeric(data):\n",
    "    convert = lambda text: int(text) if text.isdigit() else text.lower()\n",
    "    alphanum_key = lambda key: [convert(c) for c in re.split('([0-9]+)', key)]\n",
    "    return sorted(data, key=alphanum_key)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|‚ñè         | 96/7129 [00:02<01:59, 58.83it/s]"
     ]
    }
   ],
   "source": [
    "# defining the size of the image\n",
    "SIZE = 160\n",
    "color_img = []\n",
    "path = 'landscape Images/color'\n",
    "files = os.listdir(path)\n",
    "files = sorted_alphanumeric(files)\n",
    "\n",
    "for i in tqdm(files):\n",
    "    if i == '7000.jpg':\n",
    "        break\n",
    "    else:\n",
    "        img = cv2.imread(path + '/' + i, 1)\n",
    "        # open cv reads images in BGR format so we have to convert it to RGB\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        # resizing image\n",
    "        img = cv2.resize(img, (SIZE, SIZE))\n",
    "        img = img.astype('float32') / 255.0\n",
    "        color_img.append(img_to_array(img))\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gray_img = []\n",
    "path = 'landscape Images/gray'\n",
    "files = os.listdir(path)\n",
    "files = sorted_alphanumeric(files)\n",
    "for i in tqdm(files):\n",
    "    if i == '7000.jpg':\n",
    "        break\n",
    "    else:\n",
    "        img = cv2.imread(path + '/' + i, 1)\n",
    "\n",
    "        #resizing image\n",
    "        img = cv2.resize(img, (SIZE, SIZE))\n",
    "        img = img.astype('float32') / 255.0\n",
    "        gray_img.append(img_to_array(img))\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# defining function to plot images pair\n",
    "def plot_images(color, grayscale):\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.title('Color Image', color='green', fontsize=20)\n",
    "    plt.imshow(color)\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.title('Grayscale Image ', color='black', fontsize=20)\n",
    "    plt.imshow(grayscale)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "for i in range(3, 10):\n",
    "    plot_images(color_img[i], gray_img[i])\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Assuming you have loaded and preprocessed gray_img and color_img\n",
    "\n",
    "# Define the size of the image\n",
    "SIZE = 160\n",
    "\n",
    "# Assuming your dataset has 1000 images\n",
    "total_images = 7000\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "train_gray_image = gray_img[:int(0.8 * total_images)]\n",
    "train_color_image = color_img[:int(0.8 * total_images)]\n",
    "\n",
    "test_gray_image = gray_img[int(0.8 * total_images):]\n",
    "test_color_image = color_img[int(0.8 * total_images):]\n",
    "\n",
    "# Reshaping for the CNN\n",
    "train_g = np.reshape(train_gray_image, (len(train_gray_image), SIZE, SIZE, 3))\n",
    "train_c = np.reshape(train_color_image, (len(train_color_image), SIZE, SIZE, 3))\n",
    "print('Train color image shape:', train_c.shape)\n",
    "\n",
    "test_g = np.reshape(test_gray_image, (len(test_gray_image), SIZE, SIZE, 3))\n",
    "test_c = np.reshape(test_color_image, (len(test_color_image), SIZE, SIZE, 3))\n",
    "print('Test color image shape:', test_c.shape)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "\n",
    "\n",
    "def down(filters, kernel_size, apply_batch_normalization=True):\n",
    "    downsample = tf.keras.models.Sequential()\n",
    "    downsample.add(layers.Conv2D(filters, kernel_size, padding='same', strides=2))\n",
    "    if apply_batch_normalization:\n",
    "        downsample.add(layers.BatchNormalization())\n",
    "    downsample.add(keras.layers.LeakyReLU())\n",
    "    return downsample\n",
    "\n",
    "\n",
    "def up(filters, kernel_size, dropout=False):\n",
    "    upsample = tf.keras.models.Sequential()\n",
    "    upsample.add(layers.Conv2DTranspose(filters, kernel_size, padding='same', strides=2))\n",
    "    if dropout:\n",
    "        upsample.dropout(0.2)\n",
    "    upsample.add(keras.layers.LeakyReLU())\n",
    "    return upsample\n",
    "\n",
    "\n",
    "def model():\n",
    "    inputs = layers.Input(shape=[160, 160, 3])\n",
    "    d1 = down(128, (3, 3), False)(inputs)\n",
    "    d2 = down(128, (3, 3), False)(d1)\n",
    "    d3 = down(256, (3, 3), True)(d2)\n",
    "    d4 = down(512, (3, 3), True)(d3)\n",
    "\n",
    "    d5 = down(512, (3, 3), True)(d4)\n",
    "    #upsampling\n",
    "    u1 = up(512, (3, 3), False)(d5)\n",
    "    u1 = layers.concatenate([u1, d4])\n",
    "    u2 = up(256, (3, 3), False)(u1)\n",
    "    u2 = layers.concatenate([u2, d3])\n",
    "    u3 = up(128, (3, 3), False)(u2)\n",
    "    u3 = layers.concatenate([u3, d2])\n",
    "    u4 = up(128, (3, 3), False)(u3)\n",
    "    u4 = layers.concatenate([u4, d1])\n",
    "    u5 = up(3, (3, 3), False)(u4)\n",
    "    u5 = layers.concatenate([u5, inputs])\n",
    "    output = layers.Conv2D(3, (2, 2), strides=1, padding='same')(u5)\n",
    "    return tf.keras.Model(inputs=inputs, outputs=output)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = model()\n",
    "model.summary()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='mean_absolute_error',\n",
    "              metrics=['acc'])\n",
    "\n",
    "model.fit(train_g, train_c, epochs=20, batch_size=32, verbose=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# defining function to plot images pair\n",
    "def plot_images(color, grayscale, predicted):\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.title('Color Image', color='green', fontsize=20)\n",
    "    plt.imshow(color)\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.title('Grayscale Image ', color='black', fontsize=20)\n",
    "    plt.imshow(grayscale)\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.title('Predicted Image ', color='Red', fontsize=20)\n",
    "    plt.imshow(predicted)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "for i in range(50, 58):\n",
    "    predicted = np.clip(model.predict(test_gray_image[i].reshape(1, SIZE, SIZE, 3)), 0.0, 1.0).reshape(SIZE, SIZE, 3)\n",
    "    plot_images(test_color_image[i], test_gray_image[i], predicted)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "history = model.fit(train_g, train_c, epochs=2, batch_size=10, verbose=1)\n",
    "\n",
    "# Print the history\n",
    "print(history.history)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot training loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('Model Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()\n",
    "\n",
    "# Plot training accuracy (if applicable)\n",
    "if 'acc' in history.history:\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.title('Model Training Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Evaluate the model on the test set\n",
    "evaluation = model.evaluate(test_g, test_c)\n",
    "print(\"Test Loss:\", evaluation[0])\n",
    "print(\"Test Accuracy:\", evaluation[1])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Train the model with validation data\n",
    "history = model.fit(\n",
    "    train_g, train_c, epochs=20, batch_size=32,\n",
    "    validation_data=(test_g, test_c), verbose=1\n",
    "\n",
    ")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
